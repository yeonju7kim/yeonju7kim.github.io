---
layout: post
title: Distinguishing homophenes using multi-head visual-audio memory for lip reading
date: 2022-03-15 00:10:00 +0900
category: ongoing
# category: lab-paper
use_math: true
comments: true
---

본 포스팅은 아래 게시물을 참고했습니다.

- <https://www.aaai.org/AAAI22Papers/AAAI-6712.KimM.pdf>

---

연구실의 논문을 읽어보았습니다.

## Abstract

- lip reading의 문제는 크게 2개이다.
  1. speech를 완전히 표현하지 못하는 lip movement의 information 부족
  2. homophenes : 같은 입모양으로 다른 소리
- 이 논문에서는 multi-head visual-audio memory(MVM)를 사용하여 위 문제를 완화했다.
  - MVM은 audio-visual dataset으로 학습되고, audio-visual representation간의 inter-relationship을 모델링해서 audio representation을 기억한다.
  - MVM은 multi-head key memory로 구성돼서 memory로부터 candidate audio feature를 추출한다.
  - 

---

## 1. Introduction


---

## 2. Related work

---

## 3. Methods

---

## 4. Experiment

---

## 5. Conclusion
---
layout: post
title: NLP - Text preprocessing
date: 2022-03-14 00:10:00 +0900
category: nlp
use_math: true
comments: true
---

본 포스팅은 아래 위키독을 참고하여 작성되었습니다.

<https://wikidocs.net/book/2155>

## Text preprocessing

### 1. 토큰화(Tokenization)

문장은 토큰화, 정제, 정규화 과정을 거쳐야함

- 토크나이저에 따라 결과가 다름

- 토큰화에서 고려해야 할 사항

1. 구두점이나 특수 문자를 단순 제외해서는 안된다.
2. 줄임말과 단어 내의 띄어쓰기

- 토큰화 도구 NLTK word_tokenize와 WordPunctTokenizer
- 문장 토큰화도 할 수 있음 (NLTK의 sent_tokenize)

한국어
- 교착어 : 자립 형태소, 의존 형태소
- 품사 태깅 : PRP는 인칭 대명사, VBP는 동사, RB는 부사, VBG는 현재부사, IN은 전치사, NNP는 고유 명사, NNS는 복수형 명사, CC는 접속사, DT는 관사

### 2. 정제(Cleaning) and 정규화(Normalization)

- 정제(cleaning) : 갖고 있는 코퍼스로부터 노이즈 데이터를 제거한다.
- 정규화(normalization) : 표현 방법이 다른 단어들을 통합시켜서 같은 단어로 만들어준다.
- 대, 소문자 통합
- 불필요한 단어의 제거
  - 등장 빈도가 적은 단어
  - 길이가 짧은 단어(한국어에서는 안된다.)

### 3. 어간 추출(Stemming) and 표제어 추출(Lemmatization)

- 하나의 단어로 일반화시켜서 문서 내의 단어 수를 줄인다.
- 표제어 추출(Lemmatization)
  - 일반화된 단어로 변경
  - NLTK WordNetLemmatizer
- 어간 추출(stemming)
  - 중요한 단어 추출
  - PorterStemmer
- 한국어
  - 체언 : 명사, 대명사, 수사
  - 수식언 : 관형사, 부사
  - 관계언 : 조사
  - 독립언 : 감탄사
  - 용언 : 동사, 형용사

### 4. 불용어

- 큰 의미가 없는 단어 토큰을 제거하는 작업

### 5. 